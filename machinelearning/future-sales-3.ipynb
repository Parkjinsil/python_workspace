{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Introduction\n","\n","The Future Sales competition is the final assesment in the 'How to win a Data Science' course in the Advanced Machine Learning specialisation from HSE University, Moscow. The aim is to predict the monthly sales of items in specific shops, given historical data. The sale counts are clipped between 0 and 20."]},{"cell_type":"code","execution_count":2,"metadata":{"trusted":true},"outputs":[],"source":["import numpy as np \n","import pandas as pd \n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","sns.set(style=\"darkgrid\")\n","\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))"]},{"cell_type":"markdown","metadata":{},"source":["필요한 라이브러리를 불러오고 데이터 파일의 경로를 출력"]},{"cell_type":"markdown","metadata":{},"source":["# Load Data"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# load data\n","items=pd.read_csv(\"/kaggle/input/competitive-data-science-predict-future-sales/items.csv\")\n","shops=pd.read_csv(\"/kaggle/input/competitive-data-science-predict-future-sales/shops.csv\")\n","cats=pd.read_csv(\"/kaggle/input/competitive-data-science-predict-future-sales/item_categories.csv\")\n","train=pd.read_csv(\"/kaggle/input/competitive-data-science-predict-future-sales/sales_train.csv\")\n","test=pd.read_csv(\"/kaggle/input/competitive-data-science-predict-future-sales/test.csv\")"]},{"cell_type":"markdown","metadata":{},"source":["CSV 파일로부터 데이터를 로드 -> 데이터 프레임 생성됨"]},{"cell_type":"markdown","metadata":{},"source":["# 1. Data Cleaning\n","\n","We'll remove outliers, clean up some of the raw data and add some new variables to it."]},{"cell_type":"markdown","metadata":{},"source":["# Remove outliers"]},{"cell_type":"markdown","metadata":{},"source":["이상치(다른 데이터 포인트와 비교했을 때 현저히 다른 값) 제거 "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["plt.figure(figsize=(10,4))\n","plt.xlim(-100, 3000)\n","flierprops = dict(marker='o', markerfacecolor='purple', markersize=6,\n","                  linestyle='none', markeredgecolor='black')\n","sns.boxplot(x=train.item_cnt_day, flierprops=flierprops)\n","\n","plt.figure(figsize=(10,4))\n","plt.xlim(train.item_price.min(), train.item_price.max()*1.1)\n","sns.boxplot(x=train.item_price, flierprops=flierprops)"]},{"cell_type":"markdown","metadata":{},"source":["1) 첫 번째 박스 플롯 'item_cnt_day'\n","그림의 크기를 가로 10인치, 세로 4인치로 설정    \n","x축의 범위를 -100에서 30000까지 설정(박스플롯에서 데이터 분포를 더 잘 보기 위해)\n","flierprops : 이상치(outliers)의 스타일 지정\n","             원형 마커, 마커 내부 색상은 보라색, 마커 크기는 6, 선 스타일 없애고, 마커 테두리 색상 검정\n","item_cnt_day열의 값을 사용하여 박스 플롯 생성\n","\n","2) 두 번째 박스 플롯 'item_price'\n","그림의 크기를 가로 10인치 세로 4인치로 설정\n","x축의 범위를 item_price의 최소값에서 최대값의 1.1배까지 설정\n","item_price 열의 값을 사용하여 박스 플롯 생성"]},{"cell_type":"markdown","metadata":{},"source":["아이템의 가격이 300,000보다 작은 데이터 && 아이템 판매 수가 1000보다 작은 데이터만 선택 ( 이상치 제거 )"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train = train[(train.item_price < 300000 )& (train.item_cnt_day < 1000)]"]},{"cell_type":"markdown","metadata":{},"source":["아이템 가격이 0보다 큰 행만 필터링하여 train 데이터프레임에 저장 (가격이 0 이하 제거) 필터링 후 인덱스 재설정 drop=True 옵션을 사용하여 기존 인덱스 버림(필터링 후에도 인덱스가 연속적으로 유지되도록)\n","아이템 판매 수가 1미만인 경우 0으로 설정"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train = train[train.item_price > 0].reset_index(drop = True)\n","train.loc[train.item_cnt_day < 1, \"item_cnt_day\"] = 0"]},{"cell_type":"markdown","metadata":{},"source":["# Cleaning Shop Data"]},{"cell_type":"markdown","metadata":{},"source":["여러 상점이 서로 중복된 것처럼 보인다. 이는 상점이 다시 개업했거나 같은 거리나 쇼핑 센터 내에서 위치를 이동했기 때문일 수 있다"]},{"cell_type":"markdown","metadata":{},"source":["데이터셋에서 상점 ID를 업데이트하여 중복된 상점들을 하나로 통합하는 작업 수행"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Якутск Орджоникидзе, 56\n","train.loc[train.shop_id == 0, 'shop_id'] = 57\n","test.loc[test.shop_id == 0, 'shop_id'] = 57\n","# Якутск ТЦ \"Центральный\"\n","train.loc[train.shop_id == 1, 'shop_id'] = 58\n","test.loc[test.shop_id == 1, 'shop_id'] = 58\n","# Жуковский ул. Чкалова 39м²\n","train.loc[train.shop_id == 10, 'shop_id'] = 11\n","test.loc[test.shop_id == 10, 'shop_id'] = 11"]},{"cell_type":"markdown","metadata":{},"source":["train 데이터프레임에서 shop_id가 0인 행 찾아서 shop_id를 57로 변경\n","test 데이터프레임도 마찬가지\n","나머지도 같은 방식"]},{"cell_type":"markdown","metadata":{},"source":["일부 상점 이름 정리하고 city, category 정보를 shops 데이터프레임에 추가"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["shops.loc[ shops.shop_name == 'Сергиев Посад ТЦ \"7Я\"',\"shop_name\" ] = 'СергиевПосад ТЦ \"7Я\"'\n","shops[\"city\"] = shops.shop_name.str.split(\" \").map( lambda x: x[0] )\n","shops[\"category\"] = shops.shop_name.str.split(\" \").map( lambda x: x[1] )\n","shops.loc[shops.city == \"!Якутск\", \"city\"] = \"Якутск\""]},{"cell_type":"markdown","metadata":{},"source":["shop 데이터프레임에서 shop_name이 'Сергиев Посад ТЦ \"7Я\"'인 행 찾아서 shop_name 을 'СергиевПосад ТЦ \"7Я\"'로 수정 (이름 붙여쓰는 작업, 상점 이름의 일관성 유지위해)\n","shop_name을 공백' '으로 분리하여 첫 번째 단어를 city 열에 저장\n","shop_name을 공백' '으로 분리하여 두 번째 단어를 category 열에 저장\n","city 열에서 도시 이름이 \"!Якутск\"인 행 찾아서 \"Якутск\"으로 변경"]},{"cell_type":"markdown","metadata":{},"source":["특정 카테고리에 속하는 상점이 5개 이상인 경우에만 해당 카테고리 유지, 그렇지 않은 경우 'other'로 그룹화 -> 카테고리 정보 간소화"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["category = []\n","for cat in shops.category.unique():\n","    if len(shops[shops.category == cat]) >= 5:\n","        category.append(cat)\n","shops.category = shops.category.apply( lambda x: x if (x in category) else \"other\" )"]},{"cell_type":"markdown","metadata":{},"source":["빈 category 리스트 생성\n","shops 데이터프레임에서 고유한 카테고리를 추출하고, 각 카테고리를 순회\n","각 카테고리에 대해 해당 카테고리에 속하는 상점의 개수가 5개 이상인 경우\n","해당 카테고리를 category 리스트에 추가\n","'shops' 데이터프레임의 category 열을 순회해서 각 카테고리가 category 리스트에 있으면 유지 , 그렇지 않으면 other로 대체"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from sklearn.preprocessing import LabelEncoder\n","shops[\"shop_category\"] = LabelEncoder().fit_transform( shops.category )\n","shops[\"shop_city\"] = LabelEncoder().fit_transform( shops.city )\n","shops = shops[[\"shop_id\", \"shop_category\", \"shop_city\"]]"]},{"cell_type":"markdown","metadata":{},"source":["LabelEncoder() 객체를 생성하고 fit_transform 메서드 사용해서 shops.category 열의 문자열 값을 숫자형으로 변환 -> shop_category라는 새로운 열에 저장\n","shop.city도 마찬가지\n","shop_id, shop_category, chop_city 열만 선택해서 'shops' 데이터프레임 재구성"]},{"cell_type":"markdown","metadata":{},"source":["# Cleaning Item Category Data"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["cats[\"type_code\"] = cats.item_category_name.apply( lambda x: x.split(\" \")[0] ).astype(str)\n","cats.loc[ (cats.type_code == \"Игровые\")| (cats.type_code == \"Аксессуары\"), \"category\" ] = \"Игры\""]},{"cell_type":"markdown","metadata":{},"source":["cats.item_category_name 열의 값을 공백' '으로 분리하여 첫 번째 단어를 추출 -> astype(str) 사용해서 결과를 문자열로 변환 -> type_code 열에 저장\n","loc를 사용하여 type_code 열의 값이 \"Игровые\" 또는 \"Аксессуары\"인 행을 선택해서 'category' 열 값을 \"Игры\"로 설정"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["category = []\n","for cat in cats.type_code.unique():\n","    if len(cats[cats.type_code == cat]) >= 5: \n","        category.append( cat )\n","cats.type_code = cats.type_code.apply(lambda x: x if (x in category) else \"etc\")"]},{"cell_type":"markdown","metadata":{},"source":["아까 shops 데이터프레임과 마찬가지로 type_code열을 간소화\n","(5개 이상 속하면 type_code 유지, 아니면 etc로 그룹화)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["cats.type_code = LabelEncoder().fit_transform(cats.type_code)\n","cats[\"split\"] = cats.item_category_name.apply(lambda x: x.split(\"-\"))\n","cats[\"subtype\"] = cats.split.apply(lambda x: x[1].strip() if len(x) > 1 else x[0].strip())\n","cats[\"subtype_code\"] = LabelEncoder().fit_transform( cats[\"subtype\"] )\n","cats = cats[[\"item_category_id\", \"subtype_code\", \"type_code\"]]"]},{"cell_type":"markdown","metadata":{},"source":["cats.type_code열 레이블 인코딩해서 문자열 값을 숫자형 값으로 변환\n","cats_category_name을 '-'으로 분리해서 split열에 저장\n","split 열의 값이 리스트로 되어 있으므로, 리스트의 두 번째 요소를 선택해서 'subtype'열에 저장(리스트 길이가 1이하면 리스트의 첫 번째 요소 선택)\n","strip 메서드를 사용해서 문자열의 앞뒤 공백 제거\n","subtype 열의 문자열 값을 레이블 인코딩해서 숫자형 값으로 변환하여 subtype_code열에 저장\n","필요한 열만 선택해서 데이터프레임 재구성"]},{"cell_type":"markdown","metadata":{},"source":["# Cleaning Item Data"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import re\n","def name_correction(x):\n","    x = x.lower() # 모든 문자를 소문자로 변환\n","    x = x.partition('[')[0] # 대괄호로 구분하여 첫 번째 부분만 남김\n","    x = x.partition('(')[0] # 소괄호로 구분하여 첫 번째 부분만 남김\n","    x = re.sub('[^A-Za-z0-9А-Яа-я]+', ' ', x) # 특수 문자를 제거하고 공백으로 대체\n","    x = x.replace('  ', ' ') # 두 개의 공백을 하나의 공백으로 대체\n","    x = x.strip() # 앞뒤 공백을 제거\n","    return x"]},{"cell_type":"markdown","metadata":{},"source":["name_correction(x) : 문자열을 정리하고 표준화하는 작업 수행"]},{"cell_type":"markdown","metadata":{},"source":["Clean item names."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# 아이템 이름을 첫 번째 괄호로 분할 ex) \"item[description]\" -> \"item\", \"description]\"\n","items[\"name1\"], items[\"name2\"] = items.item_name.str.split(\"[\", 1).str\n","items[\"name1\"], items[\"name3\"] = items.item_name.str.split(\"(\", 1).str\n","\n","# 특수 문자를 제거하고 소문자로 변환 ex) \"Description!\" -> \"description\"\n","items[\"name2\"] = items.name2.str.replace('[^A-Za-z0-9А-Яа-я]+', \" \").str.lower()\n","items[\"name3\"] = items.name3.str.replace('[^A-Za-z0-9А-Яа-я]+', \" \").str.lower()\n","\n","# 결측값을 '0'으로 채움\n","items = items.fillna('0')\n","\n","# name_correction(x)함수를 적용하여 아이템 이름 정리\n","items[\"item_name\"] = items[\"item_name\"].apply(lambda x: name_correction(x))\n","\n","# 만약 name2가 '0'이 아니라면, 마지막 문자를 제외한 모든 문자를 반환합니다\n","# ex) \"description]\" -> \"description\"\n","items.name2 = items.name2.apply( lambda x: x[:-1] if x !=\"0\" else \"0\")"]},{"cell_type":"markdown","metadata":{},"source":["Clean item type"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["items[\"type\"] = items.name2.apply(lambda x: x[0:8] if x.split(\" \")[0] == \"xbox\" else x.split(\" \")[0] )\n","items.loc[(items.type == \"x360\") | (items.type == \"xbox360\") | (items.type == \"xbox 360\") ,\"type\"] = \"xbox 360\"\n","items.loc[ items.type == \"\", \"type\"] = \"mac\"\n","items.type = items.type.apply( lambda x: x.replace(\" \", \"\") )\n","items.loc[ (items.type == 'pc' )| (items.type == 'pс') | (items.type == \"pc\"), \"type\" ] = \"pc\"\n","items.loc[ items.type == 'рs3' , \"type\"] = \"ps3\""]},{"cell_type":"markdown","metadata":{},"source":["'items.name2'열의 각 값에 대해 첫 번째 단어가 'xbox'인 경우, 처음 8글자를 'type'에 저장 , 그렇지 않은 경우 첫 번째 단어를 'type'에 저장\n","'type'열의 값이 'x360', 'xbox360', 'xbox360'인 행을 찾아 'xbox 360'으로 통일\n","'type'열의 값이 빈 문자열 -> 'mac'으로 변환\n","'type'열의 값에서 공백 제거\n","'type'열의 값이 'pc''pс'\"pc\" -> \"pc\"로 통일\n","'type'열의 값이 'рs3' -> \"ps3\"으로 통일"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["group_sum = items.groupby([\"type\"]).agg({\"item_id\": \"count\"})\n","group_sum = group_sum.reset_index()\n","drop_cols = []\n","for cat in group_sum.type.unique():\n","    if group_sum.loc[(group_sum.type == cat), \"item_id\"].values[0] <40:\n","        drop_cols.append(cat)\n","items.name2 = items.name2.apply( lambda x: \"other\" if (x in drop_cols) else x )\n","items = items.drop([\"type\"], axis = 1)"]},{"cell_type":"markdown","metadata":{},"source":["* 'type'열 간소화\n","items 데이터프레임을 'type'열로 그룹화 -> 'item_id' 개수를 계산 -> group_sum에 저장\n","rest_index() : 그룹화된 결과를 일반 데이터프레임 형태로 변환\n","drop_cols 빈 리스트 생성\n","'type'값에 대해 'item_id' 개수가 40개 미만인 경우 해당 'type'값을 drop_cols 리스트에 추가\n","items.name2 열의 각 값에 대해 'drop_cols'리스트에 포함된 값인 경우 'other'로 변환 \n","'items' 데이터프레임에서 'type'열을 삭제"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# LabelEncoder를 사용해서 items.name2열의 문자열 값을 숫자형 값으로 변환\n","items.name2 = LabelEncoder().fit_transform(items.name2) \n","items.name3 = LabelEncoder().fit_transform(items.name3)\n","\n","# items 데이터프레임에서 'item_name'및 'name1'열 삭제 \n","# (axis=1 : 열 기준으로 삭제하겠다는 뜻, inplace=True : 원래의 데이터프레임 수정한다는 뜻)\n","items.drop([\"item_name\", \"name1\"],axis = 1, inplace= True)\n","items.head()"]},{"cell_type":"markdown","metadata":{},"source":["# Preprocessing\n","\n","Create a matrix df with every combination of month, shop and item in order of increasing month. Item_cnt_day is summed into an item_cnt_month."]},{"cell_type":"markdown","metadata":{},"source":["# 전처리 단계\n","모든 월, 상점, 아이템의 조합을 포함하는 매트릭스 데이터프레임 생성\n","아이템의 일별 판매 수량 -> 월별 판매 수량으로 합산\n","\n","* 매트릭스 데이터프레임이란?\n"," : 모든 가능한 조합을 포함하는 데이터프레임을 말함\n","ex. 월 : 1,2  /  상점 : A, B  /  아이템 : X, Y\n","   -> (1,A,X) (1,A,Y) (1,B,X) (1,B,Y) (2,A,X) (2,A,Y) (2,B,X) (2,B,Y) "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from itertools import product\n","import time\n","\n","# 현재 시간을 ts 변수에 저장하여 실행 시간 측정\n","ts = time.time() \n","\n","# 매트릭스를 생성할 리스트와 열 이름 정의\n","matrix = []\n","cols  = [\"date_block_num\", \"shop_id\", \"item_id\"]\n","\n","# 모든 조합 생성 및 리스트에 추가\n","for i in range(34):\n","    sales = train[train.date_block_num == i] \n","    matrix.append( np.array(list( product( [i], sales.shop_id.unique(), sales.item_id.unique() ) ), dtype = np.int16) )\n","\n","# 매트릭스를 데이터프레임으로 변환 (열 이름은 cols 리스트로 지정)\n","matrix = pd.DataFrame( np.vstack(matrix), columns = cols )\n","\n","# 데이터프레임의 각 열에 대해 데이터 타입을 지정 : int8\n","matrix[\"date_block_num\"] = matrix[\"date_block_num\"].astype(np.int8)\n","matrix[\"shop_id\"] = matrix[\"shop_id\"].astype(np.int8)\n","matrix[\"item_id\"] = matrix[\"item_id\"].astype(np.int16)\n","\n","# 데이터 프레임 정렬\n","matrix.sort_values( cols, inplace = True )\n","\n","# 현재 시간 - 시작 시간 = 코드 실행 시간 측정 \n","time.time()- ts"]},{"cell_type":"markdown","metadata":{},"source":["# 모든 조합 생성 및 리스트에 추가\n","'train' 데이터프레임에서 현재 'date_block_num'값에 해당하는 데이터를 필터링하여 'sales'변수에 저장\n","'sales' 데이터에서 고유한 'shop_id'와 'item_id'를 추출하고, 'itertools.product'를 사용하여 'date_block_num', 'shop_id', 'item_id'의 모든 가능한 조합을 생성\n","생성된 조합을 numpy 배열로 변환하여 matrix 리스트에 추가"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# 'train' 데이터프레임에 새로운 열 'revenue' 추가\n","train[\"revenue\"] = train[\"item_cnt_day\"] * train[\"item_price\"]\n","#  revenue = item_cnt_day * item_price "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["ts = time.time()\n","\n","# 'train' 데이터프레임을 \"date_block_num\", \"shop_id\", \"item_id\"로 그룹화 -> item_cnt_day 합계 계산\n","group = train.groupby( [\"date_block_num\", \"shop_id\", \"item_id\"] ).agg( {\"item_cnt_day\": [\"sum\"]} )\n","group.columns = [\"item_cnt_month\"] # -> 계산된 결과의 열 이름을 'item_cnt_month'로 변경\n","group.reset_index( inplace = True) # -> 인덱스 초기화, 그룹화된 결과를 일반 데이터프레임 형태로 변환\n","\n","# 그룹화된 결과를 matrix 데이터프레임과 병합 \n","matrix = pd.merge( matrix, group, on = cols, how = \"left\" )\n","# on = cols : \"date_block_num\", \"shop_id\", \"item_id\"열 기준으로 \n","# how='left': matrix 데이터프레임을 기준으로 병합하고, 매칭되지 않는 값은 'NaN'으로 남김\n","\n","# 'item_cnt_month'열의 결측값 0으로 채우고, 데이터 타입을 'np.float16'으로 변환(메모리 사용량 줄임)\n","matrix[\"item_cnt_month\"] = matrix[\"item_cnt_month\"].fillna(0).astype(np.float16)\n","\n","time.time() - ts"]},{"cell_type":"markdown","metadata":{},"source":["Create a test set for month 34."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# 'date_block_num' 열 추가 , 34로 초기화\n","test[\"date_block_num\"] = 34\n","\n","# 데이터타입 np.int8로 변환(메모리 사용량 줄임)\n","test[\"date_block_num\"] = test[\"date_block_num\"].astype(np.int8)\n","test[\"shop_id\"] = test.shop_id.astype(np.int8)\n","test[\"item_id\"] = test.item_id.astype(np.int16)"]},{"cell_type":"markdown","metadata":{},"source":["Concatenate train and test sets."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["ts = time.time()\n","\n","# 'test' 데이터프레임의 'ID'열 제거 , 'matrix' 데이터프레임에 병합\n","matrix = pd.concat([matrix, test.drop([\"ID\"],axis = 1)], ignore_index=True, sort=False, keys=cols)\n","# ignore_index=True : 병합 후 인덱스 재설정\n","# sort=False : 열 이름을 기준으로 정렬하지 않음\n","# keys=cols : 병합된 데이터프레임의 열 이름을 설정\n","\n","# 결측값 0으로 채움\n","matrix.fillna( 0, inplace = True )\n","time.time() - ts"]},{"cell_type":"markdown","metadata":{},"source":["Add shop, items and categories data onto matrix df."]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"outputs":[],"source":["ts = time.time()\n","\n","# 'matrix' 데이터프레임에 추가 정보 병합\n","# 'shops' 데이터프레임을 'matrix' 데이터프레임에 'shop_id'열을 기준으로 병합\n","# how='left' : matrix 기준으로 병합 , matrix에 없으면 'NaN'으로 남김\n","matrix = pd.merge( matrix, shops, on = [\"shop_id\"], how = \"left\" )\n","matrix = pd.merge(matrix, items, on = [\"item_id\"], how = \"left\")\n","matrix = pd.merge( matrix, cats, on = [\"item_category_id\"], how = \"left\" )\n","\n","# 데이터 타입 변환(np.int8 or np.int16으로)\n","matrix[\"shop_city\"] = matrix[\"shop_city\"].astype(np.int8)\n","matrix[\"shop_category\"] = matrix[\"shop_category\"].astype(np.int8)\n","matrix[\"item_category_id\"] = matrix[\"item_category_id\"].astype(np.int8)\n","matrix[\"subtype_code\"] = matrix[\"subtype_code\"].astype(np.int8)\n","matrix[\"name2\"] = matrix[\"name2\"].astype(np.int8)\n","matrix[\"name3\"] = matrix[\"name3\"].astype(np.int16)\n","matrix[\"type_code\"] = matrix[\"type_code\"].astype(np.int8)\n","\n","time.time() - ts"]},{"cell_type":"markdown","metadata":{},"source":["Feature Engineering\n","\n","* Add lag features to matrix df."]},{"cell_type":"markdown","metadata":{},"source":["### 랙 피처(Lag Feature)\n"," : 시계열 데이터에서 현재 시점의 데이터를 예측하기 위해 과거 시점의 데이터를 사용하는 피처를 말한다. \n","   각 랙 피처는 이전 시점의 값을 현재 시점의 피처로 사용\n","ex. 매달 판매량을 예측하는 모델에서 이전 달이나 이전 몇달의 판매량을 피처로 사용하는 것\n","\n","### 시계열 데이터(Time Series Data)\n"," : 시간의 흐름에 따라 순서대로 기록된 데이터\n","  이러한 데이터는 일정한 시간 간격으로 수집됨. 주로 시간에 따른 변화를 분석하거나 미래를 예측하는 데 사용됨"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def lag_feature( df,lags, cols ):\n","    for col in cols:\n","        print(col)  # 'cols' 리스트에 있는 각 열 이름 출력\n","        \n","        # \"date_block_num\", \"shop_id\",\"item_id\", 그리고 현재 열(col)을 포함하는 임시 데이터프레임 'tmp' 생성\n","        tmp = df[[\"date_block_num\", \"shop_id\",\"item_id\",col ]] \n","        \n","        # 랙 피처 생성 및 데이터프레임에 병합\n","        for i in lags:\n","            shifted = tmp.copy() # 'tmp' 데이터프레임을 복사\n","            \n","            # shifted 열 이름 변경\n","            shifted.columns = [\"date_block_num\", \"shop_id\", \"item_id\", col + \"_lag_\"+str(i)]\n","            # 'shifted' 데이터프레임의 'date_block_num' 열에 'i'를 더하여 랙을 만듦\n","            shifted.date_block_num = shifted.date_block_num + i\n","            \n","            # 원래의 데이터프레임(df), 'shifted'를 병합 -> 랙 피처를 추가\n","            df = pd.merge(df, shifted, on=['date_block_num','shop_id','item_id'], how='left')\n","    return df # 랙 피처가 추가된 데이터프레임 반환"]},{"cell_type":"markdown","metadata":{},"source":["lag_feature 함수 매개변수 \n","df : 랙 피처를 추가할 데이터프레임\n","lags : 랙의 크기 리스트     ex. [1,2,3] -> 1개월전 2개월전 3개월 전의 값을 사용\n","cols : 랙 피처를 생성할 열 리스트"]},{"cell_type":"markdown","metadata":{},"source":["'matrix' 데이터프레임에 'item_cnt_month' 열에 대한 1,2,3개월 전 랙 피처 추가"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["ts = time.time()\n","matrix = lag_feature( matrix, [1,2,3], [\"item_cnt_month\"] )\n","time.time() - ts"]},{"cell_type":"markdown","metadata":{},"source":["이전 달의 평균 item_cnt_month 추가"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["ts = time.time()\n","\n","# 'date_block_num'별 평균 'item_cnt_month' 계산\n","group = matrix.groupby( [\"date_block_num\"] ).agg({\"item_cnt_month\" : [\"mean\"]})\n","group.columns = [\"date_avg_item_cnt\"] # 계산된 평균 값 새로운 열로 저장\n","\n","# 그룹화된 결과(객체)를 일반 데이터프레임 형식으로 변환, 인덱스 재설정\n","group.reset_index(inplace = True) \n","\n","# matrix , 평균 값 병합\n","matrix = pd.merge(matrix, group, on = [\"date_block_num\"], how = \"left\")\n","matrix.date_avg_item_cnt = matrix[\"date_avg_item_cnt\"].astype(np.float16) # 데이터 타입 변환\n","\n","# 'date_avg_item_cnt'열에 대해 1개월 전의 값을 나타내는 랙 피처 추가\n","matrix = lag_feature( matrix, [1], [\"date_avg_item_cnt\"] ) \n","matrix.drop( [\"date_avg_item_cnt\"], axis = 1, inplace = True ) # 랙 피처 추가 후 원본 'date_avg_item_cnt'열 삭제\n","\n","time.time() - ts"]},{"cell_type":"markdown","metadata":{},"source":["월별로 item_id에 대해 item_cnt_month의 랙 값을 추가"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["ts = time.time()\n","\n","# 'date_block_num' 'item_id'로 그룹화 -> 'item_cnt_month' 평균 계산\n","group = matrix.groupby(['date_block_num', 'item_id']).agg({'item_cnt_month': ['mean']})\n","group.columns = [ 'date_item_avg_item_cnt' ] # 새로운 열로 저장\n","group.reset_index(inplace=True)\n","\n","# date_block_num 및 item_id를 기준으로 matrix 데이터프레임과 병합\n","matrix = pd.merge(matrix, group, on=['date_block_num','item_id'], how='left')\n","matrix.date_item_avg_item_cnt = matrix['date_item_avg_item_cnt'].astype(np.float16)\n","# 'date_item_avg_item_cnt' 열에 대해 1,2,3개월 전의 값을 나타내는 랙 피처 추가\n","matrix = lag_feature(matrix, [1,2,3], ['date_item_avg_item_cnt'])\n","matrix.drop(['date_item_avg_item_cnt'], axis=1, inplace=True) # 불필요한 열 삭제\n","\n","time.time() - ts"]},{"cell_type":"markdown","metadata":{},"source":["월별 및 상점 그룹마다 item_cnt_month의 랙 값을 추가"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["ts = time.time()\n","\n","group = matrix.groupby( [\"date_block_num\",\"shop_id\"] ).agg({\"item_cnt_month\" : [\"mean\"]})\n","group.columns = [\"date_shop_avg_item_cnt\"]\n","group.reset_index(inplace = True)\n","\n","matrix = pd.merge(matrix, group, on = [\"date_block_num\",\"shop_id\"], how = \"left\")\n","matrix.date_avg_item_cnt = matrix[\"date_shop_avg_item_cnt\"].astype(np.float16)\n","matrix = lag_feature( matrix, [1,2,3], [\"date_shop_avg_item_cnt\"] )\n","matrix.drop( [\"date_shop_avg_item_cnt\"], axis = 1, inplace = True )\n","time.time() - ts"]},{"cell_type":"markdown","metadata":{},"source":["월/상점/아이템 그룹에 대해 item_cnt_month의 랙 값을 추가"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["ts = time.time()\n","group = matrix.groupby( [\"date_block_num\",\"shop_id\",\"item_id\"] ).agg({\"item_cnt_month\" : [\"mean\"]})\n","group.columns = [\"date_shop_item_avg_item_cnt\"]\n","group.reset_index(inplace = True)\n","\n","matrix = pd.merge(matrix, group, on = [\"date_block_num\",\"shop_id\",\"item_id\"], how = \"left\")\n","matrix.date_avg_item_cnt = matrix[\"date_shop_item_avg_item_cnt\"].astype(np.float16)\n","matrix = lag_feature( matrix, [1,2,3], [\"date_shop_item_avg_item_cnt\"] )\n","matrix.drop( [\"date_shop_item_avg_item_cnt\"], axis = 1, inplace = True )\n","time.time() - ts"]},{"cell_type":"markdown","metadata":{},"source":["월/상점/아이템 서브타입 조합에 대해 item_cnt_month의 랙 값을 추가"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["ts = time.time()\n","group = matrix.groupby(['date_block_num', 'shop_id', 'subtype_code']).agg({'item_cnt_month': ['mean']})\n","group.columns = ['date_shop_subtype_avg_item_cnt']\n","group.reset_index(inplace=True)\n","\n","matrix = pd.merge(matrix, group, on=['date_block_num', 'shop_id', 'subtype_code'], how='left')\n","matrix.date_shop_subtype_avg_item_cnt = matrix['date_shop_subtype_avg_item_cnt'].astype(np.float16)\n","matrix = lag_feature(matrix, [1], ['date_shop_subtype_avg_item_cnt'])\n","matrix.drop(['date_shop_subtype_avg_item_cnt'], axis=1, inplace=True)\n","time.time() - ts"]},{"cell_type":"markdown","metadata":{},"source":["월/도시 그룹에 대해 item_cnt_month의 랙 값 추가"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["ts = time.time()\n","group = matrix.groupby(['date_block_num', 'shop_city']).agg({'item_cnt_month': ['mean']})\n","group.columns = ['date_city_avg_item_cnt']\n","group.reset_index(inplace=True)\n","\n","matrix = pd.merge(matrix, group, on=['date_block_num', \"shop_city\"], how='left')\n","matrix.date_city_avg_item_cnt = matrix['date_city_avg_item_cnt'].astype(np.float16)\n","matrix = lag_feature(matrix, [1], ['date_city_avg_item_cnt'])\n","matrix.drop(['date_city_avg_item_cnt'], axis=1, inplace=True)\n","time.time() - ts"]},{"cell_type":"markdown","metadata":{},"source":["월/도시/아이템 그룹에 대해 item_cnt_month의 랙 값 추가"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["ts = time.time()\n","group = matrix.groupby(['date_block_num', 'item_id', 'shop_city']).agg({'item_cnt_month': ['mean']})\n","group.columns = [ 'date_item_city_avg_item_cnt' ]\n","group.reset_index(inplace=True)\n","\n","matrix = pd.merge(matrix, group, on=['date_block_num', 'item_id', 'shop_city'], how='left')\n","matrix.date_item_city_avg_item_cnt = matrix['date_item_city_avg_item_cnt'].astype(np.float16)\n","matrix = lag_feature(matrix, [1], ['date_item_city_avg_item_cnt'])\n","matrix.drop(['date_item_city_avg_item_cnt'], axis=1, inplace=True)\n","time.time() - ts"]},{"cell_type":"markdown","metadata":{},"source":["* matrix 데이터프레임에 아이템의 평균 가격을 추가\n","* 각 월별로 아이템 가격의 랙(lag) 값을 추가 \n","* 현재 월의 평균 가격이 전체 평균 가격과 어떻게 관련되는지에 대한 델타 값(차이 값)을 추가"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["ts = time.time()\n","group = train.groupby( [\"item_id\"] ).agg({\"item_price\": [\"mean\"]})\n","group.columns = [\"item_avg_item_price\"]\n","group.reset_index(inplace = True)\n","\n","matrix = matrix.merge( group, on = [\"item_id\"], how = \"left\" )\n","matrix[\"item_avg_item_price\"] = matrix.item_avg_item_price.astype(np.float16)\n","\n","\n","group = train.groupby( [\"date_block_num\",\"item_id\"] ).agg( {\"item_price\": [\"mean\"]} )\n","group.columns = [\"date_item_avg_item_price\"]\n","group.reset_index(inplace = True)\n","\n","matrix = matrix.merge(group, on = [\"date_block_num\",\"item_id\"], how = \"left\")\n","matrix[\"date_item_avg_item_price\"] = matrix.date_item_avg_item_price.astype(np.float16)\n","lags = [1, 2, 3]\n","matrix = lag_feature( matrix, lags, [\"date_item_avg_item_price\"] )\n","for i in lags:\n","    matrix[\"delta_price_lag_\" + str(i) ] = (matrix[\"date_item_avg_item_price_lag_\" + str(i)]- matrix[\"item_avg_item_price\"] )/ matrix[\"item_avg_item_price\"]\n","\n","def select_trends(row) :\n","    for i in lags:\n","        if row[\"delta_price_lag_\" + str(i)]:\n","            return row[\"delta_price_lag_\" + str(i)]\n","    return 0\n","\n","matrix[\"delta_price_lag\"] = matrix.apply(select_trends, axis = 1)\n","matrix[\"delta_price_lag\"] = matrix.delta_price_lag.astype( np.float16 )\n","matrix[\"delta_price_lag\"].fillna( 0 ,inplace = True)\n","\n","features_to_drop = [\"item_avg_item_price\", \"date_item_avg_item_price\"]\n","for i in lags:\n","    features_to_drop.append(\"date_item_avg_item_price_lag_\" + str(i) )\n","    features_to_drop.append(\"delta_price_lag_\" + str(i) )\n","matrix.drop(features_to_drop, axis = 1, inplace = True)\n","time.time() - ts"]},{"cell_type":"markdown","metadata":{},"source":["* Add total shop revenue per month to matix df. \n","* Add lag values of revenue per month.\n","* Add delta revenue values - how current month revenue relates to global average."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["ts = time.time()\n","group = train.groupby( [\"date_block_num\",\"shop_id\"] ).agg({\"revenue\": [\"sum\"] })\n","group.columns = [\"date_shop_revenue\"]\n","group.reset_index(inplace = True)\n","\n","matrix = matrix.merge( group , on = [\"date_block_num\", \"shop_id\"], how = \"left\" )\n","matrix['date_shop_revenue'] = matrix['date_shop_revenue'].astype(np.float32)\n","\n","group = group.groupby([\"shop_id\"]).agg({ \"date_block_num\":[\"mean\"] })\n","group.columns = [\"shop_avg_revenue\"]\n","group.reset_index(inplace = True )\n","\n","matrix = matrix.merge( group, on = [\"shop_id\"], how = \"left\" )\n","matrix[\"shop_avg_revenue\"] = matrix.shop_avg_revenue.astype(np.float32)\n","matrix[\"delta_revenue\"] = (matrix['date_shop_revenue'] - matrix['shop_avg_revenue']) / matrix['shop_avg_revenue']\n","matrix[\"delta_revenue\"] = matrix[\"delta_revenue\"]. astype(np.float32)\n","\n","matrix = lag_feature(matrix, [1], [\"delta_revenue\"])\n","matrix[\"delta_revenue_lag_1\"] = matrix[\"delta_revenue_lag_1\"].astype(np.float32)\n","matrix.drop( [\"date_shop_revenue\", \"shop_avg_revenue\", \"delta_revenue\"] ,axis = 1, inplace = True)\n","time.time() - ts"]},{"cell_type":"markdown","metadata":{},"source":["Add month and number of days in each month to matrix df."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["matrix[\"month\"] = matrix[\"date_block_num\"] % 12\n","days = pd.Series([31,28,31,30,31,30,31,31,30,31,30,31])\n","matrix[\"days\"] = matrix[\"month\"].map(days).astype(np.int8)"]},{"cell_type":"markdown","metadata":{},"source":["Add the month of each shop and item first sale."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["ts = time.time()\n","matrix[\"item_shop_first_sale\"] = matrix[\"date_block_num\"] - matrix.groupby([\"item_id\",\"shop_id\"])[\"date_block_num\"].transform('min')\n","matrix[\"item_first_sale\"] = matrix[\"date_block_num\"] - matrix.groupby([\"item_id\"])[\"date_block_num\"].transform('min')\n","time.time() - ts"]},{"cell_type":"markdown","metadata":{},"source":["Delete first three months from matrix. They don't have lag values."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["ts = time.time()\n","matrix = matrix[matrix[\"date_block_num\"] > 3]\n","time.time() - ts"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["matrix.head().T"]},{"cell_type":"markdown","metadata":{},"source":["# Modelling"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import gc\n","import pickle\n","from xgboost import XGBRegressor\n","from matplotlib.pylab import rcParams\n","rcParams['figure.figsize'] = 12, 4"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["data = matrix.copy()\n","del matrix\n","gc.collect()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["data[data[\"date_block_num\"]==34].shape"]},{"cell_type":"markdown","metadata":{},"source":["Use month 34 as validation for training."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["X_train = data[data.date_block_num < 33].drop(['item_cnt_month'], axis=1)\n","Y_train = data[data.date_block_num < 33]['item_cnt_month']\n","X_valid = data[data.date_block_num == 33].drop(['item_cnt_month'], axis=1)\n","Y_valid = data[data.date_block_num == 33]['item_cnt_month']\n","X_test = data[data.date_block_num == 34].drop(['item_cnt_month'], axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["Y_train = Y_train.clip(0, 20)\n","Y_valid = Y_valid.clip(0, 20)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["del data\n","gc.collect();"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["ts = time.time()\n","\n","model = XGBRegressor(\n","    max_depth=10,\n","    n_estimators=1000,\n","    min_child_weight=0.5, \n","    colsample_bytree=0.8, \n","    subsample=0.8, \n","    eta=0.1,\n","#     tree_method='gpu_hist',\n","    seed=42)\n","\n","model.fit(\n","    X_train, \n","    Y_train, \n","    eval_metric=\"rmse\", \n","    eval_set=[(X_train, Y_train), (X_valid, Y_valid)], \n","    verbose=True, \n","    early_stopping_rounds = 20)\n","\n","time.time() - ts"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["Y_pred = model.predict(X_valid).clip(0, 20)\n","Y_test = model.predict(X_test).clip(0, 20)\n","\n","submission = pd.DataFrame({\n","    \"ID\": test.index, \n","    \"item_cnt_month\": Y_test\n","})\n","submission.to_csv('xgb_submission.csv', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from xgboost import plot_importance\n","\n","def plot_features(booster, figsize):    \n","    fig, ax = plt.subplots(1,1,figsize=figsize)\n","    return plot_importance(booster=booster, ax=ax)\n","\n","plot_features(model, (10,14))"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"databundleVersionId":868304,"sourceId":8587,"sourceType":"competition"}],"dockerImageVersionId":29981,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"}},"nbformat":4,"nbformat_minor":4}
